{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "I. Estimator for Formation energy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "column_names = [\n",
    "  'spacegroup', \n",
    "  'number_of_total_atoms', 'percent_atom_al', 'percent_atom_ga', 'percent_atom_in', \n",
    "  'lattice_vector_1_ang', 'lattice_vector_2_ang', 'lattice_vector_3_ang', \n",
    "  'lattice_angle_alpha_degree', 'lattice_angle_beta_degree', 'lattice_angle_gamma_degree'\n",
    "]\n",
    "\n",
    "x, label = pd.read_csv('train.csv')[column_names], pd.read_csv('train.csv')['formation_energy_ev_natom']\n",
    "nomad_train, nomad_test, label_train, label_test = train_test_split(\n",
    "    x, label, test_size = 0.25, random_state = 33)\n",
    "#nomad_train_label_formation = pd.read_csv('train.csv')['formation_energy_ev_natom']\n",
    "#nomad_train_label_bandgap = pd.read_csv('train.csv')['bandgap_energy_ev']                     \n",
    "nomad_predict = pd.read_csv('test.csv')[column_names]                                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1800, 11)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nomad_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2400"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nomad_train_label_formation.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(600, 11)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nomad_predict.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "WARNING:tensorflow:Using temporary folder as model directory: /tmp/tmpr0Mgv7\n",
      "INFO:tensorflow:Using config: {'_save_checkpoints_secs': 600, '_session_config': None, '_keep_checkpoint_max': 5, '_task_type': 'worker', '_is_chief': True, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f874ae27290>, '_save_checkpoints_steps': None, '_keep_checkpoint_every_n_hours': 10000, '_service': None, '_num_ps_replicas': 0, '_tf_random_seed': None, '_master': '', '_num_worker_replicas': 1, '_task_id': 0, '_log_step_count_steps': 100, '_model_dir': '/tmp/tmpr0Mgv7', '_save_summary_steps': 100}\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Saving checkpoints for 1 into /tmp/tmpr0Mgv7/model.ckpt.\n",
      "INFO:tensorflow:loss = 5.1305, step = 1\n",
      "INFO:tensorflow:global_step/sec: 27.3025\n",
      "INFO:tensorflow:loss = 0.403562, step = 101 (3.666 sec)\n",
      "INFO:tensorflow:global_step/sec: 26.2573\n",
      "INFO:tensorflow:loss = 0.52776, step = 201 (3.816 sec)\n",
      "INFO:tensorflow:global_step/sec: 25.2813\n",
      "INFO:tensorflow:loss = 0.317994, step = 301 (3.952 sec)\n",
      "INFO:tensorflow:global_step/sec: 28.1308\n",
      "INFO:tensorflow:loss = 0.396659, step = 401 (3.565 sec)\n",
      "INFO:tensorflow:global_step/sec: 26.8448\n",
      "INFO:tensorflow:loss = 0.232038, step = 501 (3.719 sec)\n",
      "INFO:tensorflow:global_step/sec: 25.9965\n",
      "INFO:tensorflow:loss = 0.373583, step = 601 (3.844 sec)\n",
      "INFO:tensorflow:global_step/sec: 28.8673\n",
      "INFO:tensorflow:loss = 0.303634, step = 701 (3.462 sec)\n",
      "INFO:tensorflow:global_step/sec: 29.6271\n",
      "INFO:tensorflow:loss = 0.430829, step = 801 (3.372 sec)\n",
      "INFO:tensorflow:global_step/sec: 26.6688\n",
      "INFO:tensorflow:loss = 0.336598, step = 901 (3.749 sec)\n",
      "INFO:tensorflow:global_step/sec: 25.8352\n",
      "INFO:tensorflow:loss = 0.390322, step = 1001 (3.875 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.8049\n",
      "INFO:tensorflow:loss = 0.304844, step = 1101 (4.382 sec)\n",
      "INFO:tensorflow:global_step/sec: 27.0355\n",
      "INFO:tensorflow:loss = 0.336107, step = 1201 (3.705 sec)\n",
      "INFO:tensorflow:global_step/sec: 27.7642\n",
      "INFO:tensorflow:loss = 0.393324, step = 1301 (3.595 sec)\n",
      "INFO:tensorflow:global_step/sec: 21.5485\n",
      "INFO:tensorflow:loss = 0.288939, step = 1401 (4.646 sec)\n",
      "INFO:tensorflow:global_step/sec: 25.8476\n",
      "INFO:tensorflow:loss = 0.398393, step = 1501 (3.864 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.6207\n",
      "INFO:tensorflow:loss = 0.291726, step = 1601 (4.427 sec)\n",
      "INFO:tensorflow:global_step/sec: 20.3752\n",
      "INFO:tensorflow:loss = 0.367686, step = 1701 (4.902 sec)\n",
      "INFO:tensorflow:global_step/sec: 29.4313\n",
      "INFO:tensorflow:loss = 0.267668, step = 1801 (3.402 sec)\n",
      "INFO:tensorflow:global_step/sec: 24.948\n",
      "INFO:tensorflow:loss = 0.258335, step = 1901 (4.006 sec)\n",
      "INFO:tensorflow:global_step/sec: 26.205\n",
      "INFO:tensorflow:loss = 0.373036, step = 2001 (3.814 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.5429\n",
      "INFO:tensorflow:loss = 0.38884, step = 2101 (4.439 sec)\n",
      "INFO:tensorflow:global_step/sec: 27.5404\n",
      "INFO:tensorflow:loss = 0.278725, step = 2201 (3.627 sec)\n",
      "INFO:tensorflow:global_step/sec: 27.5849\n",
      "INFO:tensorflow:loss = 0.278198, step = 2301 (3.625 sec)\n",
      "INFO:tensorflow:global_step/sec: 29.2582\n",
      "INFO:tensorflow:loss = 0.249106, step = 2401 (3.418 sec)\n",
      "INFO:tensorflow:global_step/sec: 29.0576\n",
      "INFO:tensorflow:loss = 0.283648, step = 2501 (3.443 sec)\n",
      "INFO:tensorflow:global_step/sec: 27.7711\n",
      "INFO:tensorflow:loss = 0.274198, step = 2601 (3.607 sec)\n",
      "INFO:tensorflow:global_step/sec: 27.542\n",
      "INFO:tensorflow:loss = 0.209859, step = 2701 (3.628 sec)\n",
      "INFO:tensorflow:global_step/sec: 18.7497\n",
      "INFO:tensorflow:loss = 0.267624, step = 2801 (5.334 sec)\n",
      "INFO:tensorflow:global_step/sec: 29.517\n",
      "INFO:tensorflow:loss = 0.304575, step = 2901 (3.390 sec)\n",
      "INFO:tensorflow:global_step/sec: 25.3054\n",
      "INFO:tensorflow:loss = 0.360739, step = 3001 (3.950 sec)\n",
      "INFO:tensorflow:global_step/sec: 29.2736\n",
      "INFO:tensorflow:loss = 0.269379, step = 3101 (3.414 sec)\n",
      "INFO:tensorflow:global_step/sec: 25.2826\n",
      "INFO:tensorflow:loss = 0.319244, step = 3201 (3.957 sec)\n",
      "INFO:tensorflow:global_step/sec: 26.5889\n",
      "INFO:tensorflow:loss = 0.254135, step = 3301 (3.763 sec)\n",
      "INFO:tensorflow:global_step/sec: 28.4894\n",
      "INFO:tensorflow:loss = 0.16534, step = 3401 (3.508 sec)\n",
      "INFO:tensorflow:global_step/sec: 25.1174\n",
      "INFO:tensorflow:loss = 0.408932, step = 3501 (3.977 sec)\n",
      "INFO:tensorflow:global_step/sec: 29.279\n",
      "INFO:tensorflow:loss = 0.358927, step = 3601 (3.418 sec)\n",
      "INFO:tensorflow:global_step/sec: 29.4343\n",
      "INFO:tensorflow:loss = 0.30422, step = 3701 (3.401 sec)\n",
      "INFO:tensorflow:global_step/sec: 29.3242\n",
      "INFO:tensorflow:loss = 0.266255, step = 3801 (3.412 sec)\n",
      "INFO:tensorflow:global_step/sec: 29.3328\n",
      "INFO:tensorflow:loss = 0.319786, step = 3901 (3.409 sec)\n",
      "INFO:tensorflow:global_step/sec: 26.6307\n",
      "INFO:tensorflow:loss = 0.248867, step = 4001 (3.748 sec)\n",
      "INFO:tensorflow:global_step/sec: 28.2\n",
      "INFO:tensorflow:loss = 0.171406, step = 4101 (3.545 sec)\n",
      "INFO:tensorflow:global_step/sec: 29.2154\n",
      "INFO:tensorflow:loss = 0.42586, step = 4201 (3.431 sec)\n",
      "INFO:tensorflow:global_step/sec: 29.3082\n",
      "INFO:tensorflow:loss = 0.347068, step = 4301 (3.409 sec)\n",
      "INFO:tensorflow:global_step/sec: 29.4853\n",
      "INFO:tensorflow:loss = 0.275237, step = 4401 (3.395 sec)\n",
      "INFO:tensorflow:global_step/sec: 29.2267\n",
      "INFO:tensorflow:loss = 0.202956, step = 4501 (3.420 sec)\n",
      "INFO:tensorflow:global_step/sec: 28.9842\n",
      "INFO:tensorflow:loss = 0.452952, step = 4601 (3.444 sec)\n",
      "INFO:tensorflow:global_step/sec: 29.4611\n",
      "INFO:tensorflow:loss = 0.16096, step = 4701 (3.393 sec)\n",
      "INFO:tensorflow:global_step/sec: 29.0955\n",
      "INFO:tensorflow:loss = 0.301568, step = 4801 (3.448 sec)\n",
      "INFO:tensorflow:global_step/sec: 29.2307\n",
      "INFO:tensorflow:loss = 0.29747, step = 4901 (3.411 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 5000 into /tmp/tmpr0Mgv7/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 0.337229.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.estimator.canned.dnn.DNNRegressor at 0x7f874ae271d0>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def create_train_input_fn(): \n",
    "    return tf.estimator.inputs.pandas_input_fn(\n",
    "        x = nomad_train,\n",
    "        y = label_train, \n",
    "        batch_size = 32,\n",
    "        num_epochs = None, # Repeat forever\n",
    "        shuffle = True)\n",
    "\n",
    "def create_test_input_fn():\n",
    "    return tf.estimator.inputs.pandas_input_fn(\n",
    "        x = nomad_test,\n",
    "        y = label_test, \n",
    "        num_epochs = 1, # Just one epoch\n",
    "        shuffle = False) # Don't shuffle so we can compare to census_test_labels later\n",
    "\n",
    "feature_columns = [\n",
    "    \n",
    "    # Bucketize the numeric column    \n",
    "    tf.feature_column.bucketized_column(\n",
    "        source_column = tf.feature_column.numeric_column('spacegroup'), \n",
    "        boundaries = [30, 50, 175, 200, 225]),\n",
    "    tf.feature_column.bucketized_column(\n",
    "        source_column = tf.feature_column.numeric_column('number_of_total_atoms'), \n",
    "        boundaries = [15, 25, 35, 45, 75]),\n",
    "    \n",
    "    tf.feature_column.bucketized_column(\n",
    "        source_column = tf.feature_column.numeric_column('percent_atom_al'), \n",
    "        boundaries = [0.1667, 0.3854, 0.5833]),\n",
    "    tf.feature_column.bucketized_column(\n",
    "        source_column = tf.feature_column.numeric_column('percent_atom_ga'), \n",
    "        boundaries = [0.0938, 0.3086, 0.4688]),\n",
    "    tf.feature_column.bucketized_column(\n",
    "        source_column = tf.feature_column.numeric_column('percent_atom_in'), \n",
    "        boundaries = [0.0625, 0.3060, 0.4688]),\n",
    "        \n",
    "    tf.feature_column.bucketized_column(\n",
    "        source_column = tf.feature_column.numeric_column('lattice_vector_1_ang'), \n",
    "        boundaries = [6.141, 9.537, 10.292]),\n",
    "    tf.feature_column.bucketized_column(\n",
    "        source_column = tf.feature_column.numeric_column('lattice_vector_2_ang'), \n",
    "        boundaries = [5.834, 6.383, 9.093]),\n",
    "    tf.feature_column.bucketized_column(\n",
    "        source_column = tf.feature_column.numeric_column('lattice_vector_3_ang'), \n",
    "        boundaries = [9.298, 10.125, 14.372]),\n",
    "    \n",
    "    # numeric features    \n",
    "    tf.feature_column.numeric_column('lattice_angle_alpha_degree'),\n",
    "    tf.feature_column.numeric_column('lattice_angle_beta_degree'),\n",
    "    tf.feature_column.numeric_column('lattice_angle_gamma_degree'),\n",
    "   \n",
    "]\n",
    "\n",
    "estimator = tf.estimator.DNNRegressor(\n",
    "    feature_columns = feature_columns,\n",
    "    hidden_units = [1024, 512, 256, 512])\n",
    "\n",
    "train_input_fn = create_train_input_fn()\n",
    "estimator.train(train_input_fn, steps = 2600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Starting evaluation at 2018-02-15-15:27:53\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tmpr0Mgv7/model.ckpt-5000\n",
      "INFO:tensorflow:Finished evaluation at 2018-02-15-15:27:53\n",
      "INFO:tensorflow:Saving dict for global step 5000: average_loss = 0.00960226, global_step = 5000, loss = 1.15227\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tmpr0Mgv7/model.ckpt-5000\n"
     ]
    }
   ],
   "source": [
    "test_input_fn = create_test_input_fn()\n",
    "estimator.evaluate(test_input_fn)\n",
    "\n",
    "def create_pred_input_fn():\n",
    "    return tf.estimator.inputs.pandas_input_fn(\n",
    "        x = nomad_predict,\n",
    "        num_epochs = 1, # Just one epoch\n",
    "        shuffle = False)\n",
    "\n",
    "pred_input_fn = create_pred_input_fn()\n",
    "#predict = estimator.predict(pred_input_fn)\n",
    "predictions = pd.DataFrame(estimator.predict(pred_input_fn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(600, 1)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/kautu/anaconda3/lib/python3.6/importlib/_bootstrap.py:205: RuntimeWarning: compiletime version 3.5 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.6\n",
      "  return f(*args, **kwds)\n",
      "TensorBoard 0.4.0rc3 at http://DRESDEN:6006 (Press CTRL+C to quit)\n",
      "^C\n"
     ]
    }
   ],
   "source": [
    "!tensorboard --logdir=graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on method predict in module tensorflow.python.estimator.estimator:\n",
      "\n",
      "predict(self, input_fn, predict_keys=None, hooks=None, checkpoint_path=None) unbound tensorflow.python.estimator.canned.dnn.DNNRegressor method\n",
      "    Yields predictions for given features.\n",
      "    \n",
      "    Args:\n",
      "      input_fn: Input function returning features which is a dictionary of\n",
      "        string feature name to `Tensor` or `SparseTensor`. If it returns a\n",
      "        tuple, first item is extracted as features. Prediction continues until\n",
      "        `input_fn` raises an end-of-input exception (`OutOfRangeError` or\n",
      "        `StopIteration`).\n",
      "      predict_keys: list of `str`, name of the keys to predict. It is used if\n",
      "        the `EstimatorSpec.predictions` is a `dict`. If `predict_keys` is used\n",
      "        then rest of the predictions will be filtered from the dictionary. If\n",
      "        `None`, returns all.\n",
      "      hooks: List of `SessionRunHook` subclass instances. Used for callbacks\n",
      "        inside the prediction call.\n",
      "      checkpoint_path: Path of a specific checkpoint to predict. If `None`, the\n",
      "        latest checkpoint in `model_dir` is used.\n",
      "    \n",
      "    Yields:\n",
      "      Evaluated values of `predictions` tensors.\n",
      "    \n",
      "    Raises:\n",
      "      ValueError: Could not find a trained model in model_dir.\n",
      "      ValueError: if batch length of predictions are not same.\n",
      "      ValueError: If there is a conflict between `predict_keys` and\n",
      "        `predictions`. For example if `predict_keys` is not `None` but\n",
      "        `EstimatorSpec.predictions` is not a `dict`.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(tf.estimator.DNNRegressor.predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.series.Series"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(label_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "II. Estimator for Bandgap energy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "WARNING:tensorflow:Using temporary folder as model directory: /tmp/tmpfYkQJ1\n",
      "INFO:tensorflow:Using config: {'_save_checkpoints_secs': 600, '_session_config': None, '_keep_checkpoint_max': 5, '_task_type': 'worker', '_is_chief': True, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f45023db250>, '_save_checkpoints_steps': None, '_keep_checkpoint_every_n_hours': 10000, '_service': None, '_num_ps_replicas': 0, '_tf_random_seed': None, '_master': '', '_num_worker_replicas': 1, '_task_id': 0, '_log_step_count_steps': 100, '_model_dir': '/tmp/tmpfYkQJ1', '_save_summary_steps': 100}\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Saving checkpoints for 1 into /tmp/tmpfYkQJ1/model.ckpt.\n",
      "INFO:tensorflow:loss = 391.575, step = 1\n",
      "INFO:tensorflow:global_step/sec: 97.5683\n",
      "INFO:tensorflow:loss = 29.0157, step = 101 (1.028 sec)\n",
      "INFO:tensorflow:global_step/sec: 82.9586\n",
      "INFO:tensorflow:loss = 30.6525, step = 201 (1.215 sec)\n",
      "INFO:tensorflow:global_step/sec: 104.075\n",
      "INFO:tensorflow:loss = 31.7412, step = 301 (0.958 sec)\n",
      "INFO:tensorflow:global_step/sec: 102.586\n",
      "INFO:tensorflow:loss = 19.7158, step = 401 (0.971 sec)\n",
      "INFO:tensorflow:global_step/sec: 84.1893\n",
      "INFO:tensorflow:loss = 10.5739, step = 501 (1.185 sec)\n",
      "INFO:tensorflow:global_step/sec: 100.032\n",
      "INFO:tensorflow:loss = 10.4543, step = 601 (1.007 sec)\n",
      "INFO:tensorflow:global_step/sec: 101.753\n",
      "INFO:tensorflow:loss = 5.87511, step = 701 (0.976 sec)\n",
      "INFO:tensorflow:global_step/sec: 89.1117\n",
      "INFO:tensorflow:loss = 9.91475, step = 801 (1.122 sec)\n",
      "INFO:tensorflow:global_step/sec: 98.7076\n",
      "INFO:tensorflow:loss = 6.87068, step = 901 (1.019 sec)\n",
      "INFO:tensorflow:global_step/sec: 103.545\n",
      "INFO:tensorflow:loss = 5.35658, step = 1001 (0.962 sec)\n",
      "INFO:tensorflow:global_step/sec: 87.778\n",
      "INFO:tensorflow:loss = 4.21221, step = 1101 (1.147 sec)\n",
      "INFO:tensorflow:global_step/sec: 104.202\n",
      "INFO:tensorflow:loss = 4.08535, step = 1201 (0.959 sec)\n",
      "INFO:tensorflow:global_step/sec: 103.787\n",
      "INFO:tensorflow:loss = 5.08784, step = 1301 (0.955 sec)\n",
      "INFO:tensorflow:global_step/sec: 89.5519\n",
      "INFO:tensorflow:loss = 4.1735, step = 1401 (1.119 sec)\n",
      "INFO:tensorflow:global_step/sec: 102.848\n",
      "INFO:tensorflow:loss = 2.91114, step = 1501 (0.978 sec)\n",
      "INFO:tensorflow:global_step/sec: 101.268\n",
      "INFO:tensorflow:loss = 3.13056, step = 1601 (0.978 sec)\n",
      "INFO:tensorflow:global_step/sec: 85.6945\n",
      "INFO:tensorflow:loss = 8.27395, step = 1701 (1.171 sec)\n",
      "INFO:tensorflow:global_step/sec: 102.632\n",
      "INFO:tensorflow:loss = 3.50003, step = 1801 (0.971 sec)\n",
      "INFO:tensorflow:global_step/sec: 101.752\n",
      "INFO:tensorflow:loss = 1.33039, step = 1901 (0.989 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 2000 into /tmp/tmpfYkQJ1/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 2.25853.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.estimator.canned.dnn.DNNRegressor at 0x7f45023db050>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "xb, bandgap = pd.read_csv('train.csv')[column_names], pd.read_csv('train.csv')['bandgap_energy_ev']\n",
    "xb_train, xb_test, bdp_train, bdp_test = train_test_split(\n",
    "    xb, bandgap, test_size = 0.25, random_state = 33)\n",
    "                  \n",
    "bandgap_predict = pd.read_csv('test.csv')[column_names]                                \n",
    "\n",
    "def create_train_input_fn(): \n",
    "    return tf.estimator.inputs.pandas_input_fn(\n",
    "        x = xb_train,\n",
    "        y = bdp_train, \n",
    "        batch_size = 32,\n",
    "        num_epochs = None, # Repeat forever\n",
    "        shuffle = True)\n",
    "\n",
    "def create_test_input_fn():\n",
    "    return tf.estimator.inputs.pandas_input_fn(\n",
    "        x = xb_test,\n",
    "        y = bdp_test, \n",
    "        num_epochs = 1, # Just one epoch\n",
    "        shuffle = False)\n",
    "\n",
    "bdp_estimator = tf.estimator.DNNRegressor(\n",
    "    feature_columns = feature_columns,\n",
    "    hidden_units = [1024, 512, 256, 128])\n",
    "\n",
    "train_input_fn = create_train_input_fn()\n",
    "bdp_estimator.train(train_input_fn, steps = 2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Starting evaluation at 2018-02-14-15:23:07\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tmpL3cLOy/model.ckpt-4000\n",
      "INFO:tensorflow:Finished evaluation at 2018-02-14-15:23:07\n",
      "INFO:tensorflow:Saving dict for global step 4000: average_loss = 0.725317, global_step = 4000, loss = 87.038\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tmpL3cLOy/model.ckpt-4000\n"
     ]
    }
   ],
   "source": [
    "test_input_fn = create_test_input_fn()\n",
    "estimator.evaluate(test_input_fn)\n",
    "\n",
    "def create_pred_input_fn():\n",
    "    return tf.estimator.inputs.pandas_input_fn(\n",
    "        x = bandgap_predict,\n",
    "        num_epochs = 1, # Just one epoch\n",
    "        shuffle = False)\n",
    "\n",
    "pred_input_fn = create_pred_input_fn()\n",
    "predict_bdg = pd.DataFrame(estimator.predict(pred_input_fn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(600, 1)"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_bdg.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sample = pd.read_csv('sample_submission.csv')\n",
    "\n",
    "sample['formation_energy_ev_natom'] = predictions\n",
    "sample['bandgap_energy_ev'] = predict_bdg\n",
    "sample.to_csv(\"submission.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "III. Estimator for Bandgap energy with atomic density"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "\n",
    "train = pd.read_csv('train.csv')[column_names]\n",
    "train = train.rename(columns={\n",
    "                             'lattice_angle_alpha_degree' : 'alpha',\n",
    "                             'lattice_angle_beta_degree' : 'beta',\n",
    "                             'lattice_angle_gamma_degree' : 'gamma'})\n",
    "\n",
    "nomad_predict = pd.read_csv('test.csv')[column_names]  \n",
    "nomad_predict = nomad_predict.rename(columns = {'lattice_angle_alpha_degree' : 'alpha',\n",
    "                                                'lattice_angle_beta_degree' : 'beta',\n",
    "                                                'lattice_angle_gamma_degree' : 'gamma'})\n",
    "\n",
    "# convert lattice angles from degrees to radians for volume calculation\n",
    "lattice_angles = ['alpha', 'beta', 'gamma']\n",
    "for lang in lattice_angles:\n",
    "    train['_'.join([lang, 'r'])] = np.pi * train[lang] / 180\n",
    "# compute the cell volumes \n",
    "train['vol'] = train['lattice_vector_1_ang'] * train['lattice_vector_2_ang'] * train['lattice_vector_3_ang'] * np.sqrt(\n",
    "    1 + 2*np.cos(train['alpha_r'])*np.cos(train['beta_r'])*np.cos(train['gamma_r'])\n",
    "      - np.cos(train['alpha_r'])**2 - np.cos(train['beta_r'])**2 - np.cos(train['gamma_r'])**2)\n",
    "# calculate the atomic density\n",
    "# this is known to correlate with stability or bonding strength\n",
    "train['atomic_density'] = train['number_of_total_atoms'] / train['vol']   \n",
    "\n",
    "#\n",
    "lattice_angles = ['alpha', 'beta', 'gamma']\n",
    "for lang in lattice_angles:\n",
    "    nomad_predict['_'.join([lang, 'r'])] = np.pi * nomad_predict[lang] / 180\n",
    "# \n",
    "nomad_predict['vol'] = nomad_predict['lattice_vector_1_ang'] * nomad_predict['lattice_vector_2_ang'] * nomad_predict['lattice_vector_3_ang'] * np.sqrt(\n",
    "    1 + 2*np.cos(nomad_predict['alpha_r'])*np.cos(nomad_predict['beta_r'])*np.cos(nomad_predict['gamma_r'])\n",
    "      - np.cos(nomad_predict['alpha_r'])**2 - np.cos(nomad_predict['beta_r'])**2 - np.cos(nomad_predict['gamma_r'])**2)\n",
    "# \n",
    "nomad_predict['atomic_density'] = nomad_predict['number_of_total_atoms'] / nomad_predict['vol']   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>spacegroup</th>\n",
       "      <th>number_of_total_atoms</th>\n",
       "      <th>percent_atom_al</th>\n",
       "      <th>percent_atom_ga</th>\n",
       "      <th>percent_atom_in</th>\n",
       "      <th>lattice_vector_1_ang</th>\n",
       "      <th>lattice_vector_2_ang</th>\n",
       "      <th>lattice_vector_3_ang</th>\n",
       "      <th>alpha</th>\n",
       "      <th>beta</th>\n",
       "      <th>gamma</th>\n",
       "      <th>alpha_r</th>\n",
       "      <th>beta_r</th>\n",
       "      <th>gamma_r</th>\n",
       "      <th>vol</th>\n",
       "      <th>atomic_density</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>33</td>\n",
       "      <td>80.0</td>\n",
       "      <td>0.6250</td>\n",
       "      <td>0.3750</td>\n",
       "      <td>0.000</td>\n",
       "      <td>9.9523</td>\n",
       "      <td>8.5513</td>\n",
       "      <td>9.1775</td>\n",
       "      <td>90.0026</td>\n",
       "      <td>90.0023</td>\n",
       "      <td>90.0017</td>\n",
       "      <td>1.570842</td>\n",
       "      <td>1.570836</td>\n",
       "      <td>1.570826</td>\n",
       "      <td>781.052081</td>\n",
       "      <td>0.102426</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>194</td>\n",
       "      <td>80.0</td>\n",
       "      <td>0.6250</td>\n",
       "      <td>0.3750</td>\n",
       "      <td>0.000</td>\n",
       "      <td>6.1840</td>\n",
       "      <td>6.1838</td>\n",
       "      <td>23.6287</td>\n",
       "      <td>90.0186</td>\n",
       "      <td>89.9980</td>\n",
       "      <td>120.0025</td>\n",
       "      <td>1.571121</td>\n",
       "      <td>1.570761</td>\n",
       "      <td>2.094439</td>\n",
       "      <td>782.500110</td>\n",
       "      <td>0.102236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>227</td>\n",
       "      <td>40.0</td>\n",
       "      <td>0.8125</td>\n",
       "      <td>0.1875</td>\n",
       "      <td>0.000</td>\n",
       "      <td>9.7510</td>\n",
       "      <td>5.6595</td>\n",
       "      <td>13.9630</td>\n",
       "      <td>90.9688</td>\n",
       "      <td>91.1228</td>\n",
       "      <td>30.5185</td>\n",
       "      <td>1.587705</td>\n",
       "      <td>1.590393</td>\n",
       "      <td>0.532648</td>\n",
       "      <td>391.227531</td>\n",
       "      <td>0.102242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>167</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0.7500</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.250</td>\n",
       "      <td>5.0036</td>\n",
       "      <td>5.0034</td>\n",
       "      <td>13.5318</td>\n",
       "      <td>89.9888</td>\n",
       "      <td>90.0119</td>\n",
       "      <td>120.0017</td>\n",
       "      <td>1.570601</td>\n",
       "      <td>1.571004</td>\n",
       "      <td>2.094425</td>\n",
       "      <td>293.377334</td>\n",
       "      <td>0.102257</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>194</td>\n",
       "      <td>80.0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.6250</td>\n",
       "      <td>0.375</td>\n",
       "      <td>6.6614</td>\n",
       "      <td>6.6612</td>\n",
       "      <td>24.5813</td>\n",
       "      <td>89.9960</td>\n",
       "      <td>90.0006</td>\n",
       "      <td>119.9893</td>\n",
       "      <td>1.570727</td>\n",
       "      <td>1.570807</td>\n",
       "      <td>2.094208</td>\n",
       "      <td>944.713843</td>\n",
       "      <td>0.084682</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   spacegroup  number_of_total_atoms  percent_atom_al  percent_atom_ga  \\\n",
       "0          33                   80.0           0.6250           0.3750   \n",
       "1         194                   80.0           0.6250           0.3750   \n",
       "2         227                   40.0           0.8125           0.1875   \n",
       "3         167                   30.0           0.7500           0.0000   \n",
       "4         194                   80.0           0.0000           0.6250   \n",
       "\n",
       "   percent_atom_in  lattice_vector_1_ang  lattice_vector_2_ang  \\\n",
       "0            0.000                9.9523                8.5513   \n",
       "1            0.000                6.1840                6.1838   \n",
       "2            0.000                9.7510                5.6595   \n",
       "3            0.250                5.0036                5.0034   \n",
       "4            0.375                6.6614                6.6612   \n",
       "\n",
       "   lattice_vector_3_ang    alpha     beta     gamma   alpha_r    beta_r  \\\n",
       "0                9.1775  90.0026  90.0023   90.0017  1.570842  1.570836   \n",
       "1               23.6287  90.0186  89.9980  120.0025  1.571121  1.570761   \n",
       "2               13.9630  90.9688  91.1228   30.5185  1.587705  1.590393   \n",
       "3               13.5318  89.9888  90.0119  120.0017  1.570601  1.571004   \n",
       "4               24.5813  89.9960  90.0006  119.9893  1.570727  1.570807   \n",
       "\n",
       "    gamma_r         vol  atomic_density  \n",
       "0  1.570826  781.052081        0.102426  \n",
       "1  2.094439  782.500110        0.102236  \n",
       "2  0.532648  391.227531        0.102242  \n",
       "3  2.094425  293.377334        0.102257  \n",
       "4  2.094208  944.713843        0.084682  "
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>spacegroup</th>\n",
       "      <th>number_of_total_atoms</th>\n",
       "      <th>percent_atom_al</th>\n",
       "      <th>percent_atom_ga</th>\n",
       "      <th>percent_atom_in</th>\n",
       "      <th>lattice_vector_1_ang</th>\n",
       "      <th>lattice_vector_2_ang</th>\n",
       "      <th>lattice_vector_3_ang</th>\n",
       "      <th>alpha</th>\n",
       "      <th>beta</th>\n",
       "      <th>gamma</th>\n",
       "      <th>alpha_r</th>\n",
       "      <th>beta_r</th>\n",
       "      <th>gamma_r</th>\n",
       "      <th>vol</th>\n",
       "      <th>atomic_density</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>33</td>\n",
       "      <td>80.0</td>\n",
       "      <td>0.1875</td>\n",
       "      <td>0.4688</td>\n",
       "      <td>0.3438</td>\n",
       "      <td>10.5381</td>\n",
       "      <td>9.0141</td>\n",
       "      <td>9.6361</td>\n",
       "      <td>89.9997</td>\n",
       "      <td>90.0003</td>\n",
       "      <td>90.0006</td>\n",
       "      <td>1.570791</td>\n",
       "      <td>1.570802</td>\n",
       "      <td>1.570807</td>\n",
       "      <td>915.347470</td>\n",
       "      <td>0.087399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>33</td>\n",
       "      <td>80.0</td>\n",
       "      <td>0.7500</td>\n",
       "      <td>0.2500</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>9.8938</td>\n",
       "      <td>8.5014</td>\n",
       "      <td>9.1298</td>\n",
       "      <td>90.0038</td>\n",
       "      <td>90.0023</td>\n",
       "      <td>90.0015</td>\n",
       "      <td>1.570863</td>\n",
       "      <td>1.570836</td>\n",
       "      <td>1.570823</td>\n",
       "      <td>767.917987</td>\n",
       "      <td>0.104178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>167</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0.6667</td>\n",
       "      <td>0.1667</td>\n",
       "      <td>0.1667</td>\n",
       "      <td>4.9811</td>\n",
       "      <td>4.9808</td>\n",
       "      <td>13.4799</td>\n",
       "      <td>89.9900</td>\n",
       "      <td>90.0109</td>\n",
       "      <td>120.0014</td>\n",
       "      <td>1.570622</td>\n",
       "      <td>1.570987</td>\n",
       "      <td>2.094420</td>\n",
       "      <td>289.624655</td>\n",
       "      <td>0.103582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>12</td>\n",
       "      <td>80.0</td>\n",
       "      <td>0.5625</td>\n",
       "      <td>0.4375</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>24.3370</td>\n",
       "      <td>6.0091</td>\n",
       "      <td>5.7620</td>\n",
       "      <td>89.9995</td>\n",
       "      <td>103.8581</td>\n",
       "      <td>90.0002</td>\n",
       "      <td>1.570788</td>\n",
       "      <td>1.812666</td>\n",
       "      <td>1.570800</td>\n",
       "      <td>818.126773</td>\n",
       "      <td>0.097784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>12</td>\n",
       "      <td>80.0</td>\n",
       "      <td>0.1875</td>\n",
       "      <td>0.5000</td>\n",
       "      <td>0.3125</td>\n",
       "      <td>24.6443</td>\n",
       "      <td>6.2906</td>\n",
       "      <td>6.1589</td>\n",
       "      <td>90.0000</td>\n",
       "      <td>104.5929</td>\n",
       "      <td>90.0001</td>\n",
       "      <td>1.570796</td>\n",
       "      <td>1.825490</td>\n",
       "      <td>1.570798</td>\n",
       "      <td>923.997043</td>\n",
       "      <td>0.086580</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   spacegroup  number_of_total_atoms  percent_atom_al  percent_atom_ga  \\\n",
       "0          33                   80.0           0.1875           0.4688   \n",
       "1          33                   80.0           0.7500           0.2500   \n",
       "2         167                   30.0           0.6667           0.1667   \n",
       "3          12                   80.0           0.5625           0.4375   \n",
       "4          12                   80.0           0.1875           0.5000   \n",
       "\n",
       "   percent_atom_in  lattice_vector_1_ang  lattice_vector_2_ang  \\\n",
       "0           0.3438               10.5381                9.0141   \n",
       "1           0.0000                9.8938                8.5014   \n",
       "2           0.1667                4.9811                4.9808   \n",
       "3           0.0000               24.3370                6.0091   \n",
       "4           0.3125               24.6443                6.2906   \n",
       "\n",
       "   lattice_vector_3_ang    alpha      beta     gamma   alpha_r    beta_r  \\\n",
       "0                9.6361  89.9997   90.0003   90.0006  1.570791  1.570802   \n",
       "1                9.1298  90.0038   90.0023   90.0015  1.570863  1.570836   \n",
       "2               13.4799  89.9900   90.0109  120.0014  1.570622  1.570987   \n",
       "3                5.7620  89.9995  103.8581   90.0002  1.570788  1.812666   \n",
       "4                6.1589  90.0000  104.5929   90.0001  1.570796  1.825490   \n",
       "\n",
       "    gamma_r         vol  atomic_density  \n",
       "0  1.570807  915.347470        0.087399  \n",
       "1  1.570823  767.917987        0.104178  \n",
       "2  2.094420  289.624655        0.103582  \n",
       "3  1.570800  818.126773        0.097784  \n",
       "4  1.570798  923.997043        0.086580  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nomad_predict.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "WARNING:tensorflow:Using temporary folder as model directory: /tmp/tmpcLHtbA\n",
      "INFO:tensorflow:Using config: {'_save_checkpoints_secs': 600, '_session_config': None, '_keep_checkpoint_max': 5, '_task_type': 'worker', '_is_chief': True, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f8748362350>, '_save_checkpoints_steps': None, '_keep_checkpoint_every_n_hours': 10000, '_service': None, '_num_ps_replicas': 0, '_tf_random_seed': None, '_master': '', '_num_worker_replicas': 1, '_task_id': 0, '_log_step_count_steps': 100, '_model_dir': '/tmp/tmpcLHtbA', '_save_summary_steps': 100}\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Saving checkpoints for 1 into /tmp/tmpcLHtbA/model.ckpt.\n",
      "INFO:tensorflow:loss = 287.761, step = 1\n",
      "INFO:tensorflow:global_step/sec: 40.337\n",
      "INFO:tensorflow:loss = 25.5019, step = 101 (2.489 sec)\n",
      "INFO:tensorflow:global_step/sec: 41.2433\n",
      "INFO:tensorflow:loss = 38.43, step = 201 (2.417 sec)\n",
      "INFO:tensorflow:global_step/sec: 41.2764\n",
      "INFO:tensorflow:loss = 36.6823, step = 301 (2.426 sec)\n",
      "INFO:tensorflow:global_step/sec: 40.957\n",
      "INFO:tensorflow:loss = 22.5575, step = 401 (2.443 sec)\n",
      "INFO:tensorflow:global_step/sec: 40.8994\n",
      "INFO:tensorflow:loss = 23.2799, step = 501 (2.443 sec)\n",
      "INFO:tensorflow:global_step/sec: 41.2949\n",
      "INFO:tensorflow:loss = 29.114, step = 601 (2.418 sec)\n",
      "INFO:tensorflow:global_step/sec: 41.1321\n",
      "INFO:tensorflow:loss = 20.5942, step = 701 (2.432 sec)\n",
      "INFO:tensorflow:global_step/sec: 40.8175\n",
      "INFO:tensorflow:loss = 23.3703, step = 801 (2.456 sec)\n",
      "INFO:tensorflow:global_step/sec: 40.9683\n",
      "INFO:tensorflow:loss = 34.4842, step = 901 (2.444 sec)\n",
      "INFO:tensorflow:global_step/sec: 40.8199\n",
      "INFO:tensorflow:loss = 27.3093, step = 1001 (2.442 sec)\n",
      "INFO:tensorflow:global_step/sec: 40.8094\n",
      "INFO:tensorflow:loss = 23.4947, step = 1101 (2.453 sec)\n",
      "INFO:tensorflow:global_step/sec: 40.6977\n",
      "INFO:tensorflow:loss = 21.8055, step = 1201 (2.459 sec)\n",
      "INFO:tensorflow:global_step/sec: 41.0556\n",
      "INFO:tensorflow:loss = 23.543, step = 1301 (2.428 sec)\n",
      "INFO:tensorflow:global_step/sec: 38.7199\n",
      "INFO:tensorflow:loss = 32.0087, step = 1401 (2.583 sec)\n",
      "INFO:tensorflow:global_step/sec: 39.889\n",
      "INFO:tensorflow:loss = 12.9916, step = 1501 (2.514 sec)\n",
      "INFO:tensorflow:global_step/sec: 40.7973\n",
      "INFO:tensorflow:loss = 38.4839, step = 1601 (2.445 sec)\n",
      "INFO:tensorflow:global_step/sec: 40.6822\n",
      "INFO:tensorflow:loss = 26.9435, step = 1701 (2.457 sec)\n",
      "INFO:tensorflow:global_step/sec: 40.7344\n",
      "INFO:tensorflow:loss = 24.1927, step = 1801 (2.456 sec)\n",
      "INFO:tensorflow:global_step/sec: 41.037\n",
      "INFO:tensorflow:loss = 13.8632, step = 1901 (2.448 sec)\n",
      "INFO:tensorflow:global_step/sec: 40.7189\n",
      "INFO:tensorflow:loss = 27.1346, step = 2001 (2.444 sec)\n",
      "INFO:tensorflow:global_step/sec: 40.7244\n",
      "INFO:tensorflow:loss = 5.8893, step = 2101 (2.457 sec)\n",
      "INFO:tensorflow:global_step/sec: 40.7095\n",
      "INFO:tensorflow:loss = 4.56238, step = 2201 (2.463 sec)\n",
      "INFO:tensorflow:global_step/sec: 40.9697\n",
      "INFO:tensorflow:loss = 4.20084, step = 2301 (2.436 sec)\n",
      "INFO:tensorflow:global_step/sec: 40.8011\n",
      "INFO:tensorflow:loss = 12.4106, step = 2401 (2.449 sec)\n",
      "INFO:tensorflow:global_step/sec: 40.5705\n",
      "INFO:tensorflow:loss = 5.3473, step = 2501 (2.468 sec)\n",
      "INFO:tensorflow:global_step/sec: 40.9622\n",
      "INFO:tensorflow:loss = 5.53741, step = 2601 (2.438 sec)\n",
      "INFO:tensorflow:global_step/sec: 40.7757\n",
      "INFO:tensorflow:loss = 8.64251, step = 2701 (2.453 sec)\n",
      "INFO:tensorflow:global_step/sec: 41.6493\n",
      "INFO:tensorflow:loss = 7.89511, step = 2801 (2.404 sec)\n",
      "INFO:tensorflow:global_step/sec: 40.6563\n",
      "INFO:tensorflow:loss = 9.47784, step = 2901 (2.463 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 3000 into /tmp/tmpcLHtbA/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 5.15373.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.estimator.canned.dnn.DNNRegressor at 0x7f874835fd10>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "density_feature_columns = [\n",
    "    \n",
    "    tf.feature_column.bucketized_column(\n",
    "        source_column = tf.feature_column.numeric_column('spacegroup'), \n",
    "        boundaries = [30, 50, 175, 200, 225]),\n",
    "    tf.feature_column.bucketized_column(\n",
    "        source_column = tf.feature_column.numeric_column('number_of_total_atoms'), \n",
    "        boundaries = [15, 25, 35, 45, 75]),\n",
    "    \n",
    "    tf.feature_column.bucketized_column(\n",
    "        source_column = tf.feature_column.numeric_column('percent_atom_al'), \n",
    "        boundaries = [0.1667, 0.3854, 0.5833]),\n",
    "    tf.feature_column.bucketized_column(\n",
    "        source_column = tf.feature_column.numeric_column('percent_atom_ga'), \n",
    "        boundaries = [0.0938, 0.3086, 0.4688]),\n",
    "    tf.feature_column.bucketized_column(\n",
    "        source_column = tf.feature_column.numeric_column('percent_atom_in'), \n",
    "        boundaries = [0.0625, 0.3060, 0.4688]),\n",
    "        \n",
    "    tf.feature_column.bucketized_column(\n",
    "        source_column = tf.feature_column.numeric_column('lattice_vector_1_ang'), \n",
    "        boundaries = [6.141, 9.537, 10.292]),\n",
    "    tf.feature_column.bucketized_column(\n",
    "        source_column = tf.feature_column.numeric_column('lattice_vector_2_ang'), \n",
    "        boundaries = [5.834, 6.383, 9.093]),\n",
    "    tf.feature_column.bucketized_column(\n",
    "        source_column = tf.feature_column.numeric_column('lattice_vector_3_ang'), \n",
    "        boundaries = [9.298, 10.125, 14.372]),\n",
    "    \n",
    "    # numeric features    \n",
    "    tf.feature_column.numeric_column('alpha'),\n",
    "    tf.feature_column.numeric_column('beta'),\n",
    "    tf.feature_column.numeric_column('gamma'),\n",
    "    \n",
    "    tf.feature_column.numeric_column('atomic_density'),\n",
    "   \n",
    "]\n",
    "\n",
    "density_column_names = [\n",
    "  'spacegroup', \n",
    "  'number_of_total_atoms', 'percent_atom_al', 'percent_atom_ga', 'percent_atom_in', \n",
    "  'lattice_vector_1_ang', 'lattice_vector_2_ang', 'lattice_vector_3_ang', \n",
    "  'alpha', 'beta', 'gamma', 'atomic_density'  \n",
    "]\n",
    "\n",
    "train_density, bandgap = train[density_column_names], pd.read_csv('train.csv')['bandgap_energy_ev']\n",
    "bg_train, bg_test, bandgap_train, bandgap_test = train_test_split(\n",
    "    train_density, bandgap, test_size = 0.25, random_state = 33)\n",
    "\n",
    "def create_train_input_fn(): \n",
    "    return tf.estimator.inputs.pandas_input_fn(\n",
    "        x = bg_train,\n",
    "        y = bandgap_train, \n",
    "        batch_size = 32,\n",
    "        num_epochs = None, # Repeat forever\n",
    "        shuffle = True)\n",
    "\n",
    "def create_test_input_fn():\n",
    "    return tf.estimator.inputs.pandas_input_fn(\n",
    "        x = bg_test,\n",
    "        y = bandgap_test, \n",
    "        num_epochs = 1, # Just one epoch\n",
    "        shuffle = False)\n",
    "\n",
    "density_estimator = tf.estimator.DNNRegressor(\n",
    "    feature_columns = density_feature_columns,\n",
    "    hidden_units = [1024, 512, 256, 128, 256])\n",
    "\n",
    "train_input_fn = create_train_input_fn()\n",
    "density_estimator.train(train_input_fn, steps = 2600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Starting evaluation at 2018-02-15-15:29:54\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tmpcLHtbA/model.ckpt-3000\n",
      "INFO:tensorflow:Finished evaluation at 2018-02-15-15:29:55\n",
      "INFO:tensorflow:Saving dict for global step 3000: average_loss = 0.149597, global_step = 3000, loss = 17.9517\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tmpcLHtbA/model.ckpt-3000\n"
     ]
    }
   ],
   "source": [
    "test_input_fn = create_test_input_fn()\n",
    "density_estimator.evaluate(test_input_fn)\n",
    "\n",
    "def create_pred_input_fn():\n",
    "    return tf.estimator.inputs.pandas_input_fn(\n",
    "        x = nomad_predict,\n",
    "        num_epochs = 1, # Just one epoch\n",
    "        shuffle = False)\n",
    "\n",
    "pred_input_fn = create_pred_input_fn()\n",
    "predict_density = pd.DataFrame(density_estimator.predict(pred_input_fn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sample = pd.read_csv('sample_submission.csv')\n",
    "\n",
    "sample['formation_energy_ev_natom'] = predictions\n",
    "sample['bandgap_energy_ev'] = predict_density\n",
    "sample.to_csv(\"submission.csv\", index = False)\n",
    "\n",
    "sample.to_csv(\"subm1024.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Ionization potentials (eV) for free atoms calculated using the local density approximation (LDA)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
